import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os
import numpy as np

# Ajout du chemin vers le dossier src
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from scraper import AgroDataScraper
from data_processor import AgroDataProcessor
from visualizations import AgroDataVisualizer

# Configuration de la page
st.set_page_config(
    page_title="Dashboard Agroalimentaire",
    page_icon="ğŸ¥¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Titre principal
st.title("ğŸ¥¬ Dashboard d'Analyse des Prix Agroalimentaires")
st.markdown("*Analyse des donnÃ©es du RÃ©seau des Nouvelles des MarchÃ©s (RNM)*")

# Sidebar pour la navigation
st.sidebar.title("Navigation")
page = st.sidebar.selectbox(
    "Choisissez une page",
    ["ğŸ  Accueil", "ğŸ“Š Dashboard", "ğŸ”„ Scraping", "ğŸ“ˆ Analyses", "â„¹ï¸ Ã€ propos"]
)

def load_data():
    """Charge les donnÃ©es depuis le fichier CSV"""
    try:
        if os.path.exists('data/processed_agro_prices.csv'):
            df = pd.read_csv('data/processed_agro_prices.csv', encoding='utf-8')
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
            return df
        else:
            return None
    except Exception as e:
        st.error(f"Erreur lors du chargement des donnÃ©es: {e}")
        return None

def home_page():
    """Page d'accueil"""
    st.header("ğŸ  Bienvenue sur le Dashboard Agroalimentaire")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ“‹ Description du projet
        
        Ce projet de scraping et d'analyse de donnÃ©es agroalimentaires collecte des informations 
        sur les prix des produits frais depuis le **RÃ©seau des Nouvelles des MarchÃ©s (RNM)** de FranceAgriMer.
        
        ### ğŸ¯ Objectifs
        
        - **Collecte automatique** des donnÃ©es de prix agroalimentaires
        - **Nettoyage et structuration** des donnÃ©es brutes
        - **Analyse statistique** des tendances de prix
        - **Visualisations interactives** pour l'exploration des donnÃ©es
        - **Dashboard web** pour la consultation des rÃ©sultats
        
        ### ğŸ“Š Sources de donnÃ©es
        
        Les donnÃ©es proviennent du site officiel du RNM qui fournit :
        - Prix des fruits et lÃ©gumes
        - Prix des produits de la mer
        - Prix de la viande
        - Prix des produits laitiers
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ› ï¸ Technologies utilisÃ©es
        
        - **Python** pour le scraping et l'analyse
        - **BeautifulSoup** pour l'extraction web
        - **Pandas** pour la manipulation de donnÃ©es
        - **Plotly** pour les visualisations
        - **Streamlit** pour l'interface web
        
        ### ğŸ“ˆ MÃ©triques clÃ©s
        
        - Mise Ã  jour quotidienne
        - Plus de 10 catÃ©gories de produits
        - Analyse multi-marchÃ©s
        """)
    
    # Statistiques si les donnÃ©es sont disponibles
    df = load_data()
    if df is not None and not df.empty:
        st.subheader("ğŸ“Š DerniÃ¨res statistiques")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total enregistrements", f"{len(df):,}")
        
        with col2:
            st.metric("Produits uniques", df['product_clean'].nunique() if 'product_clean' in df.columns else 0)
        
        with col3:
            st.metric("MarchÃ©s couverts", df['market_clean'].nunique() if 'market_clean' in df.columns else 0)
        
        with col4:
            if 'price' in df.columns:
                avg_price = df['price'].mean()
                st.metric("Prix moyen", f"{avg_price:.2f}â‚¬")

def dashboard_page():
    """Page principale du dashboard"""
    st.header("ğŸ“Š Dashboard Principal")
    
    df = load_data()
    if df is None or df.empty:
        st.warning("Aucune donnÃ©e disponible. Veuillez d'abord exÃ©cuter le scraping.")
        return
    
    # Filtres dans la sidebar
    st.sidebar.subheader("ğŸ” Filtres")
    
    # Filtre par catÃ©gorie de produit
    if 'product_category' in df.columns:
        categories = ['Toutes'] + list(df['product_category'].unique())
        selected_category = st.sidebar.selectbox("CatÃ©gorie de produit", categories)
        if selected_category != 'Toutes':
            df = df[df['product_category'] == selected_category]
    
    # Filtre par marchÃ©
    if 'market_clean' in df.columns:
        markets = ['Tous'] + list(df['market_clean'].unique())
        selected_market = st.sidebar.selectbox("MarchÃ©", markets)
        if selected_market != 'Tous':
            df = df[df['market_clean'] == selected_market]
    
    # Filtre par plage de dates
    if 'date' in df.columns:
        min_date = df['date'].min().date()
        max_date = df['date'].max().date()
        start_date, end_date = st.sidebar.date_input("Plage de dates", [min_date, max_date])
        
        df = df[(df['date'].dt.date >= start_date) & (df['date'].dt.date <= end_date)]
    
    # Onglets pour diffÃ©rentes visualisations
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ Ã‰volution", "ğŸ“Š Distribution", "ğŸ—ºï¸ Comparaisons", "ğŸ“‹ DonnÃ©es"])
    
    with tab1:
        st.subheader("Ã‰volution des prix dans le temps")
        
        if 'price' in df.columns and 'date' in df.columns:
            # Prix moyens par jour
            daily_prices = df.groupby('date')['price'].mean().reset_index()
            
            fig = px.line(daily_prices, x='date', y='price', 
                         title='Ã‰volution des prix moyens quotidiens',
                         labels={'price': 'Prix moyen (â‚¬)', 'date': 'Date'})
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Prix par catÃ©gorie
            if 'product_category' in df.columns:
                category_prices = df.groupby(['date', 'product_category'])['price'].mean().reset_index()
                
                fig2 = px.line(category_prices, x='date', y='price', color='product_category',
                             title='Ã‰volution des prix par catÃ©gorie',
                             labels={'price': 'Prix moyen (â‚¬)', 'date': 'Date', 'product_category': 'CatÃ©gorie'})
                
                st.plotly_chart(fig2, use_container_width=True)
    
    with tab2:
        st.subheader("Distribution des prix")
        
        if 'price' in df.columns:
            col1, col2 = st.columns(2)
            
            with col1:
                # Histogramme
                fig_hist = px.histogram(df, x='price', nbins=30, 
                                      title='Distribution des prix',
                                      labels={'price': 'Prix (â‚¬)', 'count': 'FrÃ©quence'})
                st.plotly_chart(fig_hist, use_container_width=True)
            
            with col2:
                # BoÃ®te Ã  moustaches
                fig_box = px.box(df, y='price', 
                               title='BoÃ®te Ã  moustaches des prix',
                               labels={'price': 'Prix (â‚¬)'})
                st.plotly_chart(fig_box, use_container_width=True)
            
            # Distribution par catÃ©gorie
            if 'product_category' in df.columns:
                fig_violin = px.violin(df, x='product_category', y='price',
                                      title='Distribution des prix par catÃ©gorie',
                                      labels={'price': 'Prix (â‚¬)', 'product_category': 'CatÃ©gorie'})
                st.plotly_chart(fig_violin, use_container_width=True)
    
    with tab3:
        st.subheader("Comparaisons entre marchÃ©s et origines")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Comparaison des marchÃ©s
            if 'market_clean' in df.columns and 'price' in df.columns:
                market_prices = df.groupby('market_clean')['price'].mean().sort_values(ascending=False).head(10)
                
                # Conversion en DataFrame pour Plotly
                market_df = market_prices.reset_index()
                market_df.columns = ['market', 'mean_price']
                
                fig_market = px.bar(market_df, x='mean_price', y='market',
                                   orientation='h', title='Top 10 marchÃ©s par prix moyen',
                                   labels={'mean_price': 'Prix moyen (â‚¬)', 'market': 'MarchÃ©'})
                st.plotly_chart(fig_market, use_container_width=True)
        
        with col2:
            # Comparaison des origines
            if 'origin' in df.columns and 'price' in df.columns:
                origin_prices = df.groupby('origin')['price'].mean().sort_values(ascending=False).head(10)
                
                # Conversion en DataFrame pour Plotly
                origin_df = origin_prices.reset_index()
                origin_df.columns = ['origin', 'mean_price']
                
                fig_origin = px.bar(origin_df, x='mean_price', y='origin',
                                   orientation='h', title='Top 10 origines par prix moyen',
                                   labels={'mean_price': 'Prix moyen (â‚¬)', 'origin': 'Origine'})
                st.plotly_chart(fig_origin, use_container_width=True)
        
        # Heatmap des prix
        if 'product_clean' in df.columns and 'market_clean' in df.columns:
            st.subheader("Heatmap des prix par produit et marchÃ©")
            
            # SÃ©lection des produits et marchÃ©s les plus frÃ©quents
            top_products = df['product_clean'].value_counts().head(8).index
            top_markets = df['market_clean'].value_counts().head(6).index
            
            filtered_df = df[
                (df['product_clean'].isin(top_products)) & 
                (df['market_clean'].isin(top_markets))
            ]
            
            pivot_data = filtered_df.pivot_table(values='price', index='product_clean', 
                                              columns='market_clean', aggfunc='mean')
            
            fig_heatmap = px.imshow(pivot_data, title='Heatmap des prix moyens',
                                  labels=dict(x="MarchÃ©", y="Produit", color="Prix moyen (â‚¬)"))
            st.plotly_chart(fig_heatmap, use_container_width=True)
    
    with tab4:
        st.subheader("Tableau des donnÃ©es")
        
        # Options d'affichage
        col1, col2 = st.columns([1, 3])
        
        with col1:
            show_rows = st.number_input("Nombre de lignes Ã  afficher", min_value=10, max_value=1000, value=50)
        
        with col2:
            search_term = st.text_input("Rechercher dans les donnÃ©es")
        
        # Filtrage des donnÃ©es
        display_df = df.copy()
        
        if search_term:
            mask = display_df.astype(str).apply(lambda x: x.str.contains(search_term, case=False)).any(axis=1)
            display_df = display_df[mask]
        
        # Affichage du tableau
        st.dataframe(display_df.head(show_rows), use_container_width=True)
        
        # Bouton de tÃ©lÃ©chargement
        csv = display_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="TÃ©lÃ©charger les donnÃ©es filtrÃ©es (CSV)",
            data=csv,
            file_name='agro_prices_filtered.csv',
            mime='text/csv'
        )

def scraping_page():
    """Page de scraping"""
    st.header("ğŸ”„ Scraping des donnÃ©es")
    
    st.markdown("""
    Cette page permet de lancer le scraping des donnÃ©es depuis le site du RNM.
    Le processus collecte les informations sur les prix des produits agroalimentaires.
    """)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("âš™ï¸ Configuration")
        
        # Options de scraping
        categories = {
            'LÃ©gumes': 'https://rnm.franceagrimer.fr/prix?LEGUMES',
            'Fruits': 'https://rnm.franceagrimer.fr/prix?FRUITS',
            'Viande': 'https://rnm.franceagrimer.fr/prix?VIANDE',
            'Beurre/Oeuf/Fromage': 'https://rnm.franceagrimer.fr/prix?BEURRE-OEUF-FROMAGE'
        }
        
        selected_categories = st.multiselect(
            "SÃ©lectionnez les catÃ©gories Ã  scraper",
            list(categories.keys()),
            default=['LÃ©gumes', 'Fruits']
        )
        
        max_products = st.number_input(
            "Nombre maximum de produits par catÃ©gorie",
            min_value=1,
            max_value=100,
            value=10
        )
        
        delay = st.number_input(
            "DÃ©lai entre les requÃªtes (secondes)",
            min_value=0,
            max_value=10,
            value=1
        )
        
        if st.button("ğŸš€ Lancer le scraping", type="primary"):
            with st.spinner("Scraping en cours..."):
                try:
                    scraper = AgroDataScraper()
                    all_data = []
                    
                    for category in selected_categories:
                        st.write(f"Scraping de la catÃ©gorie: {category}")
                        category_url = categories[category]
                        
                        # Simulation du scraping (Ã  remplacer par le vrai code)
                        category_data = scraper.scrape_category(category, category_url)
                        all_data.extend(category_data)
                    
                    if all_data:
                        # Sauvegarde des donnÃ©es
                        df = pd.DataFrame(all_data)
                        df.to_csv('data/all_agro_prices.csv', index=False, encoding='utf-8')
                        
                        st.success(f"Scraping terminÃ©! {len(all_data)} enregistrements collectÃ©s.")
                        
                        # Traitement des donnÃ©es
                        with st.spinner("Traitement des donnÃ©es..."):
                            processor = AgroDataProcessor()
                            processed_df = processor.clean_data(df)
                            enriched_df = processor.add_derived_features(processed_df)
                            enriched_df.to_csv('data/processed_agro_prices.csv', index=False, encoding='utf-8')
                        
                        st.success("DonnÃ©es traitÃ©es et sauvegardÃ©es!")
                    else:
                        st.warning("Aucune donnÃ©e collectÃ©e.")
                        
                except Exception as e:
                    st.error(f"Erreur lors du scraping: {e}")
    
    with col2:
        st.subheader("ğŸ“Š Statistiques du scraping")
        
        # Affichage des statistiques si les donnÃ©es existent
        if os.path.exists('data/all_agro_prices.csv'):
            try:
                df = pd.read_csv('data/all_agro_prices.csv', encoding='utf-8')
                
                st.metric("Total enregistrements", len(df))
                
                if 'product' in df.columns:
                    st.metric("Produits uniques", df['product'].nunique())
                
                if 'market' in df.columns:
                    st.metric("MarchÃ©s uniques", df['market'].nunique())
                
                if 'date' in df.columns:
                    st.metric("Plage de dates", f"{df['date'].min()} - {df['date'].max()}")
                
                # AperÃ§u des donnÃ©es
                st.subheader("AperÃ§u des donnÃ©es")
                st.dataframe(df.head(10))
                
            except Exception as e:
                st.error(f"Erreur lors de la lecture des donnÃ©es: {e}")
        else:
            st.info("Aucune donnÃ©e disponible. Lancez le scraping pour collecter des donnÃ©es.")

def analyses_page():
    """Page d'analyses dÃ©taillÃ©es"""
    st.header("ğŸ“ˆ Analyses DÃ©taillÃ©es")
    
    df = load_data()
    if df is None or df.empty:
        st.warning("Aucune donnÃ©e disponible pour l'analyse.")
        return
    
    # Analyse par saison
    if 'season' in df.columns and 'price' in df.columns:
        st.subheader("ğŸŒ Analyse saisonniÃ¨re")
        
        seasonal_stats = df.groupby('season')['price'].agg(['mean', 'count', 'std']).reset_index()
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_season_bar = px.bar(seasonal_stats, x='season', y='mean',
                                   title='Prix moyen par saison',
                                   labels={'mean': 'Prix moyen (â‚¬)', 'season': 'Saison'})
            st.plotly_chart(fig_season_bar, use_container_width=True)
        
        with col2:
            fig_season_count = px.bar(seasonal_stats, x='season', y='count',
                                     title='Nombre d\'observations par saison',
                                     labels={'count': 'Nombre', 'season': 'Saison'})
            st.plotly_chart(fig_season_count, use_container_width=True)
    
    # Analyse des produits les plus chers/bon marchÃ©
    if 'product_clean' in df.columns and 'price' in df.columns:
        st.subheader("ğŸ’° Analyse des prix par produit")
        
        product_stats = df.groupby('product_clean')['price'].agg(['mean', 'count']).reset_index()
        product_stats = product_stats[product_stats['count'] >= 5]  # Filtre les produits avec peu de donnÃ©es
        
        col1, col2 = st.columns(2)
        
        with col1:
            most_expensive = product_stats.nlargest(10, 'mean')
            fig_expensive = px.bar(most_expensive, x='mean', y='product_clean',
                                  orientation='h', title='Top 10 produits les plus chers',
                                  labels={'mean': 'Prix moyen (â‚¬)', 'product_clean': 'Produit'})
            st.plotly_chart(fig_expensive, use_container_width=True)
        
        with col2:
            cheapest = product_stats.nsmallest(10, 'mean')
            fig_cheap = px.bar(cheapest, x='mean', y='product_clean',
                             orientation='h', title='Top 10 produits les moins chers',
                             labels={'mean': 'Prix moyen (â‚¬)', 'product_clean': 'Produit'})
            st.plotly_chart(fig_cheap, use_container_width=True)
    
    # Analyse des corrÃ©lations
    if 'price' in df.columns:
        st.subheader("ğŸ”— Analyse des corrÃ©lations")
        
        # CrÃ©ation de variables numÃ©riques pour la corrÃ©lation
        numeric_df = df.copy()
        
        # Conversion des variables catÃ©gorielles en numÃ©riques
        if 'product_category' in numeric_df.columns:
            numeric_df['product_category_code'] = pd.Categorical(numeric_df['product_category']).codes
        
        if 'season' in numeric_df.columns:
            numeric_df['season_code'] = pd.Categorical(numeric_df['season']).codes
        
        # SÃ©lection des colonnes numÃ©riques
        numeric_cols = numeric_df.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 1:
            correlation_matrix = numeric_df[numeric_cols].corr()
            
            fig_corr = px.imshow(correlation_matrix, 
                                title='Matrice de corrÃ©lation',
                                color_continuous_scale='RdBu_r')
            st.plotly_chart(fig_corr, use_container_width=True)

def about_page():
    """Page Ã  propos"""
    st.header("â„¹ï¸ Ã€ propos du projet")
    
    st.markdown("""
    ## ğŸ¯ Objectif du projet
    
    Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'un portfolio pour dÃ©montrer des compÃ©tences en :
    - **Web scraping** avec Python
    - **Analyse de donnÃ©es** avec Pandas
    - **Visualisation** avec Plotly
    - **DÃ©veloppement web** avec Streamlit
    
    ## ğŸ“Š Source des donnÃ©es
    
    Les donnÃ©es proviennent du **RÃ©seau des Nouvelles des MarchÃ©s (RNM)**, un service public franÃ§ais 
    qui collecte et diffuse les informations sur les prix des produits agroalimentaires.
    
    ### Site source : [rnm.franceagrimer.fr](https://rnm.franceagrimer.fr)
    
    ## ğŸ› ï¸ Stack technique
    
    ### Backend
    - **Python 3.8+**
    - **BeautifulSoup4** : Parsing HTML
    - **Requests** : RequÃªtes HTTP
    - **Pandas** : Manipulation de donnÃ©es
    - **NumPy** : Calculs numÃ©riques
    
    ### Visualisation
    - **Plotly** : Graphiques interactifs
    - **Matplotlib** : Graphiques statiques
    - **Seaborn** : Visualisations statistiques
    
    ### Interface web
    - **Streamlit** : Dashboard web
    - **HTML/CSS** : Mise en page
    
    ## ğŸ“ Structure du projet
    
    ```
    agro_data_scraping/
    â”œâ”€â”€ app.py                 # Application Streamlit principale
    â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
    â”œâ”€â”€ src/                   # Code source
    â”‚   â”œâ”€â”€ scraper.py        # Script de scraping
    â”‚   â”œâ”€â”€ data_processor.py # Traitement des donnÃ©es
    â”‚   â””â”€â”€ visualizations.py # CrÃ©ation des graphiques
    â”œâ”€â”€ data/                  # DonnÃ©es collectÃ©es
    â”œâ”€â”€ static/               # Fichiers statiques
    â””â”€â”€ notebooks/             # Notebooks d'analyse
    ```
    
    ## ğŸš€ Comment utiliser
    
    1. **Installation** :
       ```bash
       pip install -r requirements.txt
       ```
    
    2. **Lancement du scraping** :
       ```bash
       python src/scraper.py
       ```
    
    3. **Traitement des donnÃ©es** :
       ```bash
       python src/data_processor.py
       ```
    
    4. **GÃ©nÃ©ration des graphiques** :
       ```bash
       python src/visualizations.py
       ```
    
    5. **Lancement du dashboard** :
       ```bash
       streamlit run app.py
       ```
    
    ## ğŸ“ˆ MÃ©triques et KPIs
    
    - **FrÃ©quence de mise Ã  jour** : Quotidienne
    - **Nombre de catÃ©gories** : 4+ (LÃ©gumes, Fruits, Viande, Produits laitiers)
    - **Nombre de marchÃ©s** : 20+
    - **PÃ©riode couverte** : Variable selon les donnÃ©es disponibles
    
    ## ğŸ”® Ã‰volutions possibles
    
    - [ ] Ajout de plus de catÃ©gories de produits
    - [ ] IntÃ©gration de donnÃ©es historiques
    - [ ] ModÃ©lisation prÃ©dictive des prix
    - [ ] Alertes sur les variations de prix
    - [ ] API REST pour l'accÃ¨s aux donnÃ©es
    
    ## ğŸ‘¤ Auteur
    
    Projet dÃ©veloppÃ© pour dÃ©montrer des compÃ©tences en data science et web scraping.
    
    ---
    *Ce projet est Ã  but Ã©ducatif et respecte les conditions d'utilisation du site source.*
    """)

# Navigation entre les pages
if page == "ğŸ  Accueil":
    home_page()
elif page == "ğŸ“Š Dashboard":
    dashboard_page()
elif page == "ğŸ”„ Scraping":
    scraping_page()
elif page == "ğŸ“ˆ Analyses":
    analyses_page()
elif page == "â„¹ï¸ Ã€ propos":
    about_page()

# Footer
st.markdown("---")
st.markdown("ğŸ¥¬ Dashboard Agroalimentaire | DonnÃ©es RNM FranceAgriMer | Projet Portfolio")
